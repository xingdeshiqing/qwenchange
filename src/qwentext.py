# D:\qwenchange\simple_describe.py
import os
import torch
import json
from PIL import Image
from datetime import datetime
from pathlib import Path
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor


def load_model():
    """åŠ è½½æ¨¡å‹"""
    model_path = Path(r"D:\qwenchange\models\qwen_vl")

    print("ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹...")

    # åŠ è½½å¤„ç†å™¨
    processor = AutoProcessor.from_pretrained(
        model_path,
        trust_remote_code=True
    )

    # åŠ è½½æ¨¡å‹ï¼ˆä½¿ç”¨åŠç²¾åº¦ï¼‰
    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
        model_path,
        torch_dtype=torch.float16,
        device_map="auto",
        trust_remote_code=True
    )

    model.eval()
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

    if torch.cuda.is_available():
        print(f"ğŸ“Š ä½¿ç”¨è®¾å¤‡: GPU ({torch.cuda.get_device_name(0)})")
    else:
        print("âš ï¸  ä½¿ç”¨è®¾å¤‡: CPU")

    return model, processor


def describe_image(image_path, model, processor, question=None):
    """æè¿°å•å¼ å›¾ç‰‡"""
    try:
        # æ‰“å¼€å›¾ç‰‡
        image = Image.open(image_path).convert("RGB")
        print(f"ğŸ“· å¤„ç†å›¾ç‰‡: {os.path.basename(image_path)}")

        # é»˜è®¤é—®é¢˜
        if question is None:
            question = "ç®€å•æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚"

        # æ„å»ºæ¶ˆæ¯
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image"},
                    {"type": "text", "text": question}
                ]
            }
        ]

        # é¢„å¤„ç†
        text = processor.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )

        inputs = processor(text=text, images=image, return_tensors="pt")

        # ç§»åŠ¨åˆ°GPU
        if torch.cuda.is_available():
            inputs = inputs.to("cuda")

        print("ğŸ¤– ç”Ÿæˆæè¿°ä¸­...")

        # ç”Ÿæˆæè¿°ï¼ˆä½¿ç”¨è¾ƒçŸ­é•¿åº¦ï¼‰
        with torch.no_grad():
            generated_ids = model.generate(
                **inputs,
                max_new_tokens=256,  # ç¼©çŸ­ç”Ÿæˆé•¿åº¦
                do_sample=True,
                temperature=0.7,
                top_p=0.9
            )

        # è§£ç ç»“æœ
        generated_text = processor.batch_decode(
            generated_ids,
            skip_special_tokens=True
        )[0]

        # æå–åŠ©æ‰‹å›å¤
        if "assistant" in generated_text:
            description = generated_text.split("assistant")[-1].strip()
        else:
            description = generated_text.strip()

        # æ„å»ºç»“æœ
        result = {
            "image_path": str(image_path),
            "image_name": os.path.basename(image_path),
            "image_size": f"{image.size[0]}x{image.size[1]}",
            "question": question,
            "description": description,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "model": "Qwen2.5-VL-7B-Instruct"
        }

        print(f"âœ… æè¿°å®Œæˆ: {description[:100]}...")
        return result

    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        return None


def save_json(result, output_dir):
    """ä¿å­˜ä¸ºJSONæ–‡ä»¶"""
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # ç”Ÿæˆæ–‡ä»¶å
    image_name = Path(result["image_path"]).stem
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{image_name}_{timestamp}.json"
    output_path = output_dir / filename

    # ä¿å­˜JSON
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"ğŸ’¾ ç»“æœä¿å­˜åˆ°: {output_path}")
    return output_path


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("Qwen2.5-VL å›¾ç‰‡æè¿°å·¥å…·")
    print("=" * 50)

    # è®¾ç½®è·¯å¾„
    image_path = r"D:\qwenchange\data\images\1.jpg"
    output_dir = r"D:\qwenchange\data\results"

    # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
    if not os.path.exists(image_path):
        print(f"âŒ å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
        print(f"ğŸ“ è¯·æ£€æŸ¥ç›®å½•: {os.path.dirname(image_path)}")
        # åˆ—å‡ºç›®å½•ä¸­çš„æ–‡ä»¶
        if os.path.exists(os.path.dirname(image_path)):
            print("ç›®å½•ä¸­çš„æ–‡ä»¶:")
            for f in os.listdir(os.path.dirname(image_path)):
                print(f"  - {f}")
        return

    # åŠ è½½æ¨¡å‹
    model, processor = load_model()

    # æè¿°å›¾ç‰‡
    result = describe_image(image_path, model, processor)

    if result:
        # ä¿å­˜JSON
        save_json(result, output_dir)

        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        print("\n" + "=" * 50)
        print("ğŸ“Š ç»“æœæ‘˜è¦")
        print("=" * 50)
        print(f"ğŸ“· å›¾ç‰‡: {result['image_name']}")
        print(f"ğŸ“ å°ºå¯¸: {result['image_size']}")
        print(f"â“ é—®é¢˜: {result['question']}")
        print(f"ğŸ“ æè¿°: {result['description']}")
        print("=" * 50)
    else:
        print("âŒ å›¾ç‰‡æè¿°å¤±è´¥")


if __name__ == "__main__":
    main()